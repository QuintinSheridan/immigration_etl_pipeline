{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Us Weather and Immigragration Study\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project an ETL Pipeline is created to to combine data from 4 sifferent data sets: immigration, temperature, demographics, and airports to asses immigration paterns in the US.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import psycopg2\n",
    "import boto3\n",
    "from pyspark.sql import SparkSession\n",
    "from io import StringIO # python3; python2: BytesIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get environment variables for connecting to AWS\n",
    "#AWS_SECRET = os.environ['AWS_SECRET']\n",
    "#AWS_KEY = os.environ['AWS_KEY']\n",
    "#DB_USER = os.environ['DB_USER']\n",
    "#DB_PASSWORD = os.environ['DB_PASSWORD']\n",
    "#ARN = os.environ['ARN']\n",
    "\n",
    "AWS_SECRET = 'AKIAXBEQDW5I6X2BDYF7'\n",
    "AWS_KEY = 'q4JwS2TEUaznc1+uLjcUFPR/XhsUrGchhZedCYEI'\n",
    "DB = 'dev'\n",
    "DB_USER = 'dwhuser'\n",
    "DB_PASSWORD = 'dwhBub42'\n",
    "HOST = 'redshift-cluster-1.ca7m8qui9aaj.us-west-2.redshift.amazonaws.com'\n",
    "ARN='arn:aws:iam::483486054225:role/dwhRole'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "In thi project imigration, temperature, demographic, and airport data will be processes into a form that is consumable by data analysts to analyze immigration trends in the US.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Temperature Data\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "pd_temp_df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "#df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Imigration Data\n",
    "sprk_im_df = spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Demographic Data\n",
    "pd_demographic_df = pd.read_csv('us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in Airport Data\n",
    "pd_airport_df = pd.read_csv('airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper function to write dfs to S3 storage for staging\n",
    "def write_to_staging(df, bucket, csv_name):\n",
    "    \"\"\"Function that writes a df to csv in S3\n",
    "    Args:\n",
    "        df (dataframe): pandas dataframe\n",
    "        bucket (str): S3 bucket name\n",
    "        csv_name (str): name for output csv\n",
    "    \"\"\"\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    s3_resource = boto3.resource('s3',\n",
    "                                aws_access_key_id=AWS_SECRET, \n",
    "                                aws_secret_access_key=AWS_KEY, \n",
    "                                region_name='us-west-2')\n",
    "    s3_resource.Object(bucket, csv_name).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599212, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dt', 'AverageTemperature', 'AverageTemperatureUncertainty', 'City',\n",
       "       'Country', 'Latitude', 'Longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_temp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# countries = pd_temp_df['Country'].unique()\n",
    "# countries.sort()\n",
    "# countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687289, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_temp_df = pd_temp_df[pd_temp_df['Country']=='United States']\n",
    "pd_temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661524, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_temp_df = pd_temp_df.dropna()\n",
    "pd_temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555  1820-01-01               2.101                          3.217  Abilene   \n",
       "47556  1820-02-01               6.926                          2.853  Abilene   \n",
       "\n",
       "             Country Latitude Longitude  \n",
       "47555  United States   32.95N   100.53W  \n",
       "47556  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_temp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# format lat and lon\n",
    "pd_temp_df['Latitude'] = pd_temp_df['Latitude'].str[:-1] \n",
    "pd_temp_df['Longitude'] = '-' + pd_temp_df['Longitude'].str[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert from metric to english units\n",
    "pd_temp_df['AverageTemperature'] = pd_temp_df['AverageTemperature'].apply(lambda x: (1.8*x)+32) \n",
    "pd_temp_df['AverageTemperatureUncertainty'] = pd_temp_df['AverageTemperatureUncertainty'].apply(lambda x: (1.8*x)+32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove country\n",
    "pd_temp_df = pd_temp_df.drop('Country', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>35.7818</td>\n",
       "      <td>37.7906</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>44.4668</td>\n",
       "      <td>37.1354</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555  1820-01-01             35.7818                        37.7906  Abilene   \n",
       "47556  1820-02-01             44.4668                        37.1354  Abilene   \n",
       "\n",
       "      Latitude Longitude  \n",
       "47555    32.95   -100.53  \n",
       "47556    32.95   -100.53  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_temp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_data_dict = {\n",
    "                          'dt': 'date' , \n",
    "                          'AverageTemperature': 'average temperature in Ferenheit' , \n",
    "                          'AverageTemperatureUncertainty': 'temperature uncertainty in Ferenheit', \n",
    "                          'City': 'City', \n",
    "                          'Latitude': 'latitude', \n",
    "                          'Longitude': 'longitude'\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47555      1820-01-01\n",
       "47556      1820-02-01\n",
       "47557      1820-03-01\n",
       "47558      1820-04-01\n",
       "47559      1820-05-01\n",
       "47560      1820-06-01\n",
       "47561      1820-07-01\n",
       "47562      1820-08-01\n",
       "47563      1820-09-01\n",
       "47564      1820-10-01\n",
       "47565      1820-11-01\n",
       "47566      1820-12-01\n",
       "47567      1821-01-01\n",
       "47568      1821-02-01\n",
       "47569      1821-03-01\n",
       "47570      1821-04-01\n",
       "47571      1821-05-01\n",
       "47572      1821-06-01\n",
       "47573      1821-07-01\n",
       "47574      1821-08-01\n",
       "47575      1821-09-01\n",
       "47576      1821-10-01\n",
       "47577      1821-11-01\n",
       "47578      1821-12-01\n",
       "47579      1822-01-01\n",
       "47580      1822-02-01\n",
       "47581      1822-03-01\n",
       "47582      1822-04-01\n",
       "47583      1822-05-01\n",
       "47584      1822-06-01\n",
       "              ...    \n",
       "8439217    2011-04-01\n",
       "8439218    2011-05-01\n",
       "8439219    2011-06-01\n",
       "8439220    2011-07-01\n",
       "8439221    2011-08-01\n",
       "8439222    2011-09-01\n",
       "8439223    2011-10-01\n",
       "8439224    2011-11-01\n",
       "8439225    2011-12-01\n",
       "8439226    2012-01-01\n",
       "8439227    2012-02-01\n",
       "8439228    2012-03-01\n",
       "8439229    2012-04-01\n",
       "8439230    2012-05-01\n",
       "8439231    2012-06-01\n",
       "8439232    2012-07-01\n",
       "8439233    2012-08-01\n",
       "8439234    2012-09-01\n",
       "8439235    2012-10-01\n",
       "8439236    2012-11-01\n",
       "8439237    2012-12-01\n",
       "8439238    2013-01-01\n",
       "8439239    2013-02-01\n",
       "8439240    2013-03-01\n",
       "8439241    2013-04-01\n",
       "8439242    2013-05-01\n",
       "8439243    2013-06-01\n",
       "8439244    2013-07-01\n",
       "8439245    2013-08-01\n",
       "8439246    2013-09-01\n",
       "Name: dt, Length: 661524, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_temp_df['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We can see that the temperature data only goes to 2013,\n",
    "# but the immigration data is from 2016 so we will not use \n",
    "# the temperature data in future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Imigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for col in sprk_im_df.limit(1).toPandas().columns:\n",
    "#    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create a table view to query gainst\n",
    "sprk_im_df.createOrReplaceTempView(\"immigration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i94yr\n",
       "0  2016.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do not need to keep i94yr as it has a single value\n",
    "years = spark.sql('''\n",
    "    SELECT \n",
    "        DISTINCT i94yr\n",
    "    FROM\n",
    "        immigration\n",
    "''')\n",
    "years.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94mon\n",
       "0     4.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do not need to keep i94month as it has a single value\n",
    "months = spark.sql('''\n",
    "    SELECT \n",
    "        DISTINCT i94mon\n",
    "    FROM\n",
    "        immigration\n",
    "''')\n",
    "months.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# we do not need to keep i94month as it has a single value\n",
    "# arrdate = spark.sql('''\n",
    "#     SELECT \n",
    "#         DISTINCT arrdate\n",
    "#     FROM\n",
    "#         immigration\n",
    "# ''')\n",
    "# arrdate.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94visa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94visa\n",
       "0      1.0\n",
       "1      3.0\n",
       "2      2.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94visa = spark.sql('''\n",
    "    SELECT \n",
    "        DISTINCT i94visa\n",
    "    FROM\n",
    "        immigration\n",
    "''')\n",
    "i94visa.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# visatype = spark.sql('''\n",
    "#     SELECT \n",
    "#         DISTINCT visatype\n",
    "#     FROM\n",
    "#         immigration\n",
    "# ''')\n",
    "# visatype.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depDate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>245.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94cit i94port  i94mode  arrdate  i94res i94addr  depDate  i94bir  i94visa  \\\n",
       "0   245.0     LOS      1.0  20574.0   438.0      CA  20582.0    40.0      1.0   \n",
       "1   245.0     LOS      1.0  20574.0   438.0      NV  20591.0    32.0      1.0   \n",
       "2   245.0     LOS      1.0  20574.0   438.0      WA  20582.0    29.0      1.0   \n",
       "\n",
       "  gender  \n",
       "0      F  \n",
       "1      F  \n",
       "2      M  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data dict for kept columns and use to remove unneccesary columns\n",
    "immigration_data_dict = {'i94cit': 'city code' , \n",
    "                          'i94port': 'port code' , \n",
    "                          'i94mode':  'transportation code', \n",
    "                          'arrdate': 'arrival date',\n",
    "                          'i94res': 'country code for immigrant', \n",
    "                          'i94addr': 'state code', \n",
    "                          'depDate': 'departure date',\n",
    "                          'i94bir': 'immigrant age', \n",
    "                          'i94visa': 'visa type',\n",
    "                          'gender': 'gender'}\n",
    "\n",
    "imigration_keep_cols = list(immigration_data_dict.keys())\n",
    "\n",
    "sprk_im_df = sprk_im_df.select(imigration_keep_cols)\n",
    "\n",
    "sprk_im_df.limit(3).toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_im_df = sprk_im_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096313, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_im_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop rows with null values\n",
    "pd_im_df = pd_im_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LOS', 'HHW', 'HOU', 'NEW', 'WAS', 'MIA', 'DAL', 'NYC', 'ORL',\n",
       "       'SFR', 'CHI', 'TOR', 'SEA', 'BOS', 'PHI', 'SAJ', 'CLG', 'DET',\n",
       "       'MON', 'VCV', 'MAA', 'POO', 'PHO', 'HAM', 'DEN', 'FTL', 'ATL',\n",
       "       'CLT', 'CIN', 'LVG', 'SDP', 'SLC', 'NAS', 'SPM', 'DUB', 'AGA',\n",
       "       'SAI', 'EDA', 'OTT', 'TAM', 'NCA', 'SNJ', 'WIN', 'HAL', 'OGG',\n",
       "       'FMY', 'CLM', 'MIL', 'OAK', 'WPB', 'PSP', 'LIH', 'NSV', 'X96',\n",
       "       'AUS', 'BAL', 'ROC', 'RDU', 'KOA', 'NOL', 'XXX', 'STT', 'W55',\n",
       "       'SNA', 'YGF', 'OPF', 'CHR', 'INT', 'BUF', 'SAC', 'ONT', 'BRO',\n",
       "       'LAR', 'SAA', 'STL', 'HAR', 'CLE', 'SRQ', 'INP', 'KAN', 'PIT',\n",
       "       'MCA', 'FOK', 'LNB', 'SFB', 'X44', 'CRQ', 'PEM', 'ELP', 'PEV',\n",
       "       'BLA', 'HIG', 'CHM', 'DER', 'AXB', 'SWE', 'VIC', 'MEM', 'LYN',\n",
       "       'PEN', 'PHU', 'POR', 'SAV', 'NOR', 'SUM', 'BEE', 'STR', 'RIF',\n",
       "       'SYR', 'EPI', 'GAL', 'ABG', 'MDT', 'PTL', 'HID', 'BTN', 'OTM',\n",
       "       'ANA', 'KEY', 'SSM', 'DOU', 'HTM', 'NOG', 'LEW', 'PBB', 'CLS',\n",
       "       'DAC', 'FTC', 'GPM', 'LAU', 'NEC', 'NIA', 'PHR', 'ROU', 'SKA',\n",
       "       'SYS', 'THO', 'WHO', 'AND', 'CAL', 'COB', 'DLR', 'LCB', 'LLB',\n",
       "       'MAD', 'ORO', 'ROM', 'TEC', 'YSL', 'BOA', 'ANZ', 'EGP', 'LUK',\n",
       "       'PIE', 'ROS', 'AGN', 'PIR', 'FER', 'JKM', 'NAC', 'ALC', 'CNA',\n",
       "       'DNA', 'MAS', 'MOO', 'MOR', 'NRN', 'OGD', 'PDN', 'PNH', 'PRE',\n",
       "       'ROO', 'TRO', 'VIB', 'WAL', 'WBE', 'BAU', 'BWA', 'CHT', 'DLB',\n",
       "       'DNS', 'DVL', 'FRT', 'HNN', 'HNS', 'HVR', 'LAN', 'MET', 'SPE',\n",
       "       'WAR', 'COL', 'TUR', 'ABS', 'BWM', 'RAY', 'SLU', 'VCB', 'PGR',\n",
       "       'BEB', 'LOI', 'FWA', 'NRG', 'ADT', 'CRY', 'MRC', 'SHR', 'FTK',\n",
       "       'NIG', 'VNB', 'NOO', 'FAL', 'FTF', 'RIO', 'LWT', 'BGM', 'HPN',\n",
       "       'SHA', 'WIL', 'HEF', 'HSV', 'BRG', 'BED', 'DAB', 'TUC', 'FPR',\n",
       "       'JAC', 'CAE', 'FRB', 'ANC', 'RNO', 'SGR', 'SWF', 'PTK', 'MWH',\n",
       "       'CHA', 'CHS', 'MLB', 'BQN', 'VNY', 'ICT', 'JFA', 'SPO', 'MYR',\n",
       "       'ADS', '5T6', 'FAR', 'LOU', 'TKI', 'BDL', 'PVD', 'YIP', 'GSP',\n",
       "       'BHX', 'MND', 'FCA', 'ATW', 'MHT', 'NYL', 'LEX', 'APF', 'MMU',\n",
       "       'CRP', 'MAF', 'YHC', 'PSM', 'WLL', 'RST', 'ABQ', 'HEL', 'RYY',\n",
       "       'NC8', 'MTH', 'ADW', 'SGJ', 'OMA', 'DPA', '5KE', 'PHF'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_im_df['i94port'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop any duplicate rows\n",
    "pd_im_df = pd_im_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write the cleaned imigration to csv in staging\n",
    "write_to_staging(pd_im_df, 'qscapstone', 'immigration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                  name  elevation_ft continent  \\\n",
       "0   00A       heliport     Total Rf Heliport          11.0       NaN   \n",
       "1  00AA  small_airport  Aero B Ranch Airport        3435.0       NaN   \n",
       "\n",
       "  iso_country iso_region municipality gps_code iata_code local_code  \\\n",
       "0          US      US-PA     Bensalem      00A       NaN        00A   \n",
       "1          US      US-KS        Leoti     00AA       NaN       00AA   \n",
       "\n",
       "                          coordinates  \n",
       "0  -74.93360137939453, 40.07080078125  \n",
       "1              -101.473911, 38.704022  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_airport_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55075, 12)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_airport_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#pd_airport_df['iso_country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_airport_df = pd_airport_df[(pd_airport_df['iso_country']=='US') & (pd_airport_df['iata_code'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2019, 12)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_airport_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>07FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>07FA</td>\n",
       "      <td>OCA</td>\n",
       "      <td>07FA</td>\n",
       "      <td>-80.274803161621, 25.325399398804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>305.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Pilot Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PQS</td>\n",
       "      <td>0AK</td>\n",
       "      <td>-162.899994, 61.934601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ident           type                     name  elevation_ft continent  \\\n",
       "440  07FA  small_airport  Ocean Reef Club Airport           8.0       NaN   \n",
       "594   0AK  small_airport    Pilot Station Airport         305.0       NaN   \n",
       "\n",
       "    iso_country iso_region   municipality gps_code iata_code local_code  \\\n",
       "440          US      US-FL      Key Largo     07FA       OCA       07FA   \n",
       "594          US      US-AK  Pilot Station      NaN       PQS        0AK   \n",
       "\n",
       "                           coordinates  \n",
       "440  -80.274803161621, 25.325399398804  \n",
       "594             -162.899994, 61.934601  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_airport_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_airport_df['same_id'] = pd_airport_df['ident'] == pd_airport_df['local_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_airport_df['same_id'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>same_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>2IG4</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ed-Air Airport</td>\n",
       "      <td>426.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IN</td>\n",
       "      <td>Oaktown</td>\n",
       "      <td>I20</td>\n",
       "      <td>OTN</td>\n",
       "      <td>I20</td>\n",
       "      <td>-87.4997024536, 38.851398468</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>2Z1</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Entrance Island Seaplane Base</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Entrance Island</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-133.43848, 57.412201</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>AHT</td>\n",
       "      <td>closed</td>\n",
       "      <td>Amchitka Army Airfield</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>PAHT</td>\n",
       "      <td>AHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.259166667, 51.3777777778</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11498</th>\n",
       "      <td>ARX</td>\n",
       "      <td>closed</td>\n",
       "      <td>Asbury Park Neptune Air Terminal</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NJ</td>\n",
       "      <td>Asbury Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.0908333333, 40.2193055556</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11676</th>\n",
       "      <td>AUS</td>\n",
       "      <td>closed</td>\n",
       "      <td>Austin Robert Mueller Municipal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KAUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.6997852325, 30.2987223546</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident           type                              name  elevation_ft  \\\n",
       "3143   2IG4  small_airport                    Ed-Air Airport         426.0   \n",
       "3643    2Z1  seaplane_base     Entrance Island Seaplane Base           0.0   \n",
       "10470   AHT         closed            Amchitka Army Airfield         215.0   \n",
       "11498   ARX         closed  Asbury Park Neptune Air Terminal          95.0   \n",
       "11676   AUS         closed   Austin Robert Mueller Municipal           NaN   \n",
       "\n",
       "      continent iso_country iso_region     municipality gps_code iata_code  \\\n",
       "3143        NaN          US      US-IN          Oaktown      I20       OTN   \n",
       "3643        NaN          US      US-AK  Entrance Island      NaN       HBH   \n",
       "10470       NaN          US      US-AK  Amchitka Island     PAHT       AHT   \n",
       "11498       NaN          US      US-NJ      Asbury Park      NaN       ARX   \n",
       "11676       NaN          US      US-TX              NaN     KAUS       AUS   \n",
       "\n",
       "      local_code                    coordinates  same_id  \n",
       "3143         I20   -87.4997024536, 38.851398468    False  \n",
       "3643         NaN          -133.43848, 57.412201    False  \n",
       "10470        NaN   179.259166667, 51.3777777778    False  \n",
       "11498        NaN  -74.0908333333, 40.2193055556    False  \n",
       "11676        NaN  -97.6997852325, 30.2987223546    False  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_airport_df[pd_airport_df['same_id']==False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5KE', '5T6', 'ABG', 'ABQ', 'ABS', 'ADS', 'ADT', 'ADW', 'AGA',\n",
       "       'AGN', 'ALC', 'ANA', 'ANC', 'AND', 'ANZ', 'APF', 'ATL', 'ATW',\n",
       "       'AUS', 'AXB', 'BAL', 'BAU', 'BDL', 'BEB', 'BED', 'BEE', 'BGM',\n",
       "       'BHX', 'BLA', 'BOA', 'BOS', 'BQN', 'BRG', 'BRO', 'BTN', 'BUF',\n",
       "       'BWA', 'BWM', 'CAE', 'CAL', 'CHA', 'CHI', 'CHM', 'CHR', 'CHS',\n",
       "       'CHT', 'CIN', 'CLE', 'CLG', 'CLM', 'CLS', 'CLT', 'CNA', 'COB',\n",
       "       'COL', 'CRP', 'CRQ', 'CRY', 'DAB', 'DAC', 'DAL', 'DEN', 'DER',\n",
       "       'DET', 'DLB', 'DLR', 'DNA', 'DNS', 'DOU', 'DPA', 'DUB', 'DVL',\n",
       "       'EDA', 'EGP', 'ELP', 'EPI', 'FAL', 'FAR', 'FCA', 'FER', 'FMY',\n",
       "       'FOK', 'FPR', 'FRB', 'FRT', 'FTC', 'FTF', 'FTK', 'FTL', 'FWA',\n",
       "       'GAL', 'GPM', 'GSP', 'HAL', 'HAM', 'HAR', 'HEF', 'HEL', 'HHW',\n",
       "       'HID', 'HIG', 'HNN', 'HNS', 'HOU', 'HPN', 'HSV', 'HTM', 'HVR',\n",
       "       'ICT', 'INP', 'INT', 'JAC', 'JFA', 'JKM', 'KAN', 'KEY', 'KOA',\n",
       "       'LAN', 'LAR', 'LAU', 'LCB', 'LEW', 'LEX', 'LIH', 'LLB', 'LNB',\n",
       "       'LOI', 'LOS', 'LOU', 'LUK', 'LVG', 'LWT', 'LYN', 'MAA', 'MAD',\n",
       "       'MAF', 'MAS', 'MCA', 'MDT', 'MEM', 'MET', 'MHT', 'MIA', 'MIL',\n",
       "       'MLB', 'MMU', 'MND', 'MON', 'MOO', 'MOR', 'MRC', 'MTH', 'MWH',\n",
       "       'MYR', 'NAC', 'NAS', 'NC8', 'NCA', 'NEC', 'NEW', 'NIA', 'NIG',\n",
       "       'NOG', 'NOL', 'NOO', 'NOR', 'NRG', 'NRN', 'NSV', 'NYC', 'NYL',\n",
       "       'OAK', 'OGD', 'OGG', 'OMA', 'ONT', 'OPF', 'ORL', 'ORO', 'OTM',\n",
       "       'OTT', 'PBB', 'PDN', 'PEM', 'PEN', 'PEV', 'PGR', 'PHF', 'PHI',\n",
       "       'PHO', 'PHR', 'PHU', 'PIE', 'PIR', 'PIT', 'PNH', 'POO', 'POR',\n",
       "       'PRE', 'PSM', 'PSP', 'PTK', 'PTL', 'PVD', 'RAY', 'RDU', 'RIF',\n",
       "       'RIO', 'RNO', 'ROC', 'ROM', 'ROO', 'ROS', 'ROU', 'RST', 'RYY',\n",
       "       'SAA', 'SAC', 'SAI', 'SAJ', 'SAV', 'SDP', 'SEA', 'SFB', 'SFR',\n",
       "       'SGJ', 'SGR', 'SHA', 'SHR', 'SKA', 'SLC', 'SLU', 'SNA', 'SNJ',\n",
       "       'SPE', 'SPM', 'SPO', 'SRQ', 'SSM', 'STL', 'STR', 'STT', 'SUM',\n",
       "       'SWE', 'SWF', 'SYR', 'SYS', 'TAM', 'TEC', 'THO', 'TKI', 'TOR',\n",
       "       'TRO', 'TUC', 'TUR', 'VCB', 'VCV', 'VIB', 'VIC', 'VNB', 'VNY',\n",
       "       'W55', 'WAL', 'WAR', 'WAS', 'WBE', 'WHO', 'WIL', 'WIN', 'WLL',\n",
       "       'WPB', 'X44', 'X96', 'XXX', 'YGF', 'YHC', 'YIP', 'YSL'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_ports = pd_im_df['i94port'].unique()\n",
    "im_ports.sort()\n",
    "im_ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAF', 'AAP', 'ABE', ..., 'ZNC', 'ZPH', 'ZZV'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iata_codes = pd_airport_df['iata_code'].unique()\n",
    "iata_codes.sort()\n",
    "iata_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can see that we can join the immigration data to the airport data on pd_im_df.i94port = pd_airport_df.iata_code\n",
    "len(list(set(iata_codes).intersection(set(im_ports))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>same_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>07FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>07FA</td>\n",
       "      <td>OCA</td>\n",
       "      <td>07FA</td>\n",
       "      <td>-80.274803161621, 25.325399398804</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ident           type                     name  elevation_ft continent  \\\n",
       "440  07FA  small_airport  Ocean Reef Club Airport           8.0       NaN   \n",
       "\n",
       "    iso_country iso_region municipality gps_code iata_code local_code  \\\n",
       "440          US      US-FL    Key Largo     07FA       OCA       07FA   \n",
       "\n",
       "                           coordinates  same_id  \n",
       "440  -80.274803161621, 25.325399398804     True  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_airport_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_airport_df['latitude'] = pd_airport_df['coordinates'].str.split(',').str[1]\n",
    "pd_airport_df['longitude'] = pd_airport_df['coordinates'].str.split(',').str[0]\n",
    "#pd_airport_df['coordinates'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>07FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>OCA</td>\n",
       "      <td>25.325399398804</td>\n",
       "      <td>-80.274803161621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Pilot Station</td>\n",
       "      <td>PQS</td>\n",
       "      <td>61.934601</td>\n",
       "      <td>-162.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0CO2</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Crested Butte</td>\n",
       "      <td>CSE</td>\n",
       "      <td>38.851918</td>\n",
       "      <td>-106.928341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>0TE7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Johnson City</td>\n",
       "      <td>JCY</td>\n",
       "      <td>30.251800537100003</td>\n",
       "      <td>-98.62249755859999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>13MA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Metropolitan Airport</td>\n",
       "      <td>US-MA</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>PMX</td>\n",
       "      <td>42.223300933800004</td>\n",
       "      <td>-72.31140136719999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ident           type                     name iso_region   municipality  \\\n",
       "440   07FA  small_airport  Ocean Reef Club Airport      US-FL      Key Largo   \n",
       "594    0AK  small_airport    Pilot Station Airport      US-AK  Pilot Station   \n",
       "673   0CO2  small_airport    Crested Butte Airpark      US-CO  Crested Butte   \n",
       "1088  0TE7  small_airport        LBJ Ranch Airport      US-TX   Johnson City   \n",
       "1402  13MA  small_airport     Metropolitan Airport      US-MA         Palmer   \n",
       "\n",
       "     iata_code             latitude           longitude  \n",
       "440        OCA      25.325399398804    -80.274803161621  \n",
       "594        PQS            61.934601         -162.899994  \n",
       "673        CSE            38.851918         -106.928341  \n",
       "1088       JCY   30.251800537100003  -98.62249755859999  \n",
       "1402       PMX   42.223300933800004  -72.31140136719999  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_data_dict = {\n",
    "    'ident': 'pkey dentifier', \n",
    "    'type': 'type of airport', \n",
    "    'name': 'airport name', \n",
    "    'iso_region': 'airport region', \n",
    "    'municipality': 'airport municipality', \n",
    "    'iata_code': 'code for airport, maps to i94port in imigration',\n",
    "    'latitude': 'latitude',\n",
    "    'longitude': 'longitude'  \n",
    "}\n",
    "\n",
    "air_keep_cols = list(air_data_dict.keys())\n",
    "pd_airport_df = pd_airport_df[air_keep_cols]\n",
    "pd_airport_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write airports to s3 for staging\n",
    "pd_airport_df = pd_airport_df.drop_duplicates()\n",
    "write_to_staging(pd_airport_df, 'qscapstone', 'airports.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Demographic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City;State;Median Age;Male Population;Female Population;Total Population;Number of Veterans;Foreign-born;Average Household Size;State Code;Race;Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring;Maryland;33.8;40601;41862;82463;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  City;State;Median Age;Male Population;Female Population;Total Population;Number of Veterans;Foreign-born;Average Household Size;State Code;Race;Count\n",
       "0  Silver Spring;Maryland;33.8;40601;41862;82463;...                                                                                                   "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_demographic_df.head(1)\n",
    "\n",
    "# heare we can see that we will need to perform some string parsing \n",
    "# to get this dataset into a usable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State',\n",
       " 'Median_Age',\n",
       " 'Male_Population',\n",
       " 'Female_Population',\n",
       " 'Total_Population',\n",
       " 'Number_of_Veterans',\n",
       " 'Foreign_born',\n",
       " 'Average_Household_Size',\n",
       " 'State_Code',\n",
       " 'Race',\n",
       " 'Count']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_string = pd_demographic_df.columns[0]\n",
    "original_col = col_string\n",
    "# split column names out\n",
    "cols = col_string.split(';')\n",
    "# replace spaces with underscores\n",
    "for i in range(len(cols)):\n",
    "    cols[i] = cols[i].replace(' ', '_')\n",
    "    cols[i] = cols[i].replace('-', '_')\n",
    "\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_demographic_df = pd_demographic_df[original_col].str.split(';',expand=True)\n",
    "pd_demographic_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write demographics to csv in s3 storage\n",
    "pd_demographic_df = pd_demographic_df.drop_duplicates()\n",
    "write_to_staging(pd_demographic_df, 'qscapstone', 'demographics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The data model for this project will conform to a star schema where the facts table is the immigration data which is connected to dimension tables for airports and demographics.\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "1) Clean data sets and create staging tables in s3 Bucket \"qscapstone\"\n",
    "    immigration.csv\n",
    "    airports.csv\n",
    "    demographics.csv\n",
    "    \n",
    "2) Read data sets into spark for joining/querying\n",
    "3) Create immigration_facts facts table\n",
    "3) Create airports dimensions table which joins to immigration_facts\n",
    "4) Create demographics dimension table which joins to immigration_facts\n",
    "5) Create cube tables for airports to serve analytics on travel patterns\n",
    "6) Create cube tables for demographics to serve analytics on travel patterns\n",
    "7) write all tables to Redshift \n",
    "7) Run tests to ensure data integrity/pipline success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def connect_to_reshift(host, dbname, user, password, port):\n",
    "    \"\"\"Function that returns a psycopg2 db connection\n",
    "    Args:\n",
    "        host (str): host\n",
    "        dbname (str): database\n",
    "        password (str): user password\n",
    "        port (int): \n",
    "    \"\"\"\n",
    "    connection_string = f'host={host} dbname={dbname} user={user} password={password} port={port}'\n",
    "    conn = psycopg2.connect(connection_string)\n",
    "    \n",
    "    return conn       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def drop_tables(conn, tables):\n",
    "    \"\"\"Function that drops all tables\n",
    "    Args:\n",
    "        conn (connection): psycopg2 connection\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    for table in tables:\n",
    "        try:\n",
    "            query = 'DROP TABLE ' + table\n",
    "            cur.execute(query)\n",
    "        except:\n",
    "            conn.rollback()\n",
    "        \n",
    "    conn.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "drop_tables(conn, ['staging_airports', 'staging_demographics', 'staging_immigration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_tables(conn):\n",
    "    '''Function that creates tables in redshift\n",
    "    Args:\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    create_staging_immigration = '''\n",
    "    CREATE TABLE IF NOT EXISTS staging_immigration(\n",
    "        im_id integer identity(0,1) PRIMARY KEY,\n",
    "        i94cit varchar, \n",
    "        i94port varchar NOT NULL, \n",
    "        i94mode varchar,\n",
    "        arrdate varchar,\n",
    "        i94res varchar,\n",
    "        i94addr varchar,\n",
    "        depDate varchar,\n",
    "        i94bir varchar,\n",
    "        i94visa varchar,\n",
    "        gender varchar\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    create_staging_airports = '''\n",
    "    CREATE TABLE IF NOT EXISTS staging_airports(\n",
    "        ident varchar PRIMARY KEY,\n",
    "        type varchar,\n",
    "        name varchar, \n",
    "        iso_region varchar, \n",
    "        municipality varchar, \n",
    "        iata_code varchar, \n",
    "        latitude float, \n",
    "        longitude float\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    create_staging_demographics = '''\n",
    "    CREATE TABLE IF NOT EXISTS staging_demographics(\n",
    "         city_id integer identity(0,1) PRIMARY KEY,\n",
    "         City varchar,\n",
    "         State varchar,\n",
    "         Median_Age real,\n",
    "         Male_Population integer,\n",
    "         Female_Population integer,\n",
    "         Total_Population integer,\n",
    "         Number_of_Veterans integer,\n",
    "         Foreign_born integer,\n",
    "         Average_Household_Size real,\n",
    "         State_Code varchar,\n",
    "         Race varchar,\n",
    "         Count integer,\n",
    "         UNIQUE(City, State)\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    create_immigration_facts = '''\n",
    "    CREATE TABLE IF NOT EXISTS immigration_facts(\n",
    "        im_id PRIMARY KEY,\n",
    "        i94port varchar NOT NULL,\n",
    "        city_id integer NOT NULL,\n",
    "        i94cit varchar, \n",
    "        i94mode varchar,\n",
    "        arrdate varchar,\n",
    "        i94res varchar,\n",
    "        i94addr varchar,\n",
    "        depDate varchar,\n",
    "        i94bir varchar,\n",
    "        i94visa varchar,\n",
    "        gender varchar\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    create_airports_dimension = '''\n",
    "    CREATE TABLE IF NOT EXISTS airports_dimension(\n",
    "        ident varchar NOT NULL,\n",
    "        im_id integer NOT NULL,\n",
    "        type varchar,\n",
    "        name varchar, \n",
    "        iso_region varchar, \n",
    "        municipality varchar, \n",
    "        iata_code varchar, \n",
    "        latitude float, \n",
    "        longitude float\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    create_demographics_dimension = '''\n",
    "    CREATE TABLE IF NOT EXISTS staging_demographics(\n",
    "         city_id integer NOT NULL,\n",
    "         im_id integer NOT NULL,\n",
    "         City varchar,\n",
    "         State varchar,\n",
    "         Median_Age real,\n",
    "         Male_Population integer,\n",
    "         Female_Population integer,\n",
    "         Total_Population integer,\n",
    "         Number_of_Veterans integer,\n",
    "         Foreign_born integer,\n",
    "         Average_Household_Size real,\n",
    "         State_Code varchar,\n",
    "         Race varchar,\n",
    "         Count integer,\n",
    "         UNIQUE(City, State)\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "#     create_queries = [create_staging_immigration, \n",
    "#                       create_staging_airports, \n",
    "#                       create_staging_demographics,\n",
    "#                       create_immigration_dimension, \n",
    "#                       create_airports_dimension, \n",
    "#                       create_demographics_dimension]\n",
    "    \n",
    "    create_queries = [create_immigration_facts, \n",
    "                      create_airports_dimension, \n",
    "                      create_demographics_dimension]\n",
    "    \n",
    "    for query in create_queries:\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "        except:\n",
    "            conn.rollback()\n",
    "            print('error in making table: ', query)\n",
    "            \n",
    "            \n",
    "    conn.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn = connect_to_reshift(HOST, DB, DB_USER, DB_PASSWORD, 5439)\n",
    "create_tables(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cur.execute('SElect * from staging_demographics')\n",
    "# result = cur.fetchone()\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def copy_staging(conn, bucket, csv_files, tables):\n",
    "    '''Function that copies csv files to staging tables\n",
    "    Args:\n",
    "        conn (connection): pyscopg2 connection\n",
    "        bucket (str): aws bucket\n",
    "        csv_files ([str]): list of csv_files\n",
    "        tables ([str]): corresponding tables for copying\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    staging_copy = \"\"\"\n",
    "    COPY {}\n",
    "    FROM '{}'\n",
    "    IAM_ROLE '{}'\n",
    "    REGION 'us-west-2'\n",
    "    CSV IGNOREHEADER 1;\n",
    "    \"\"\"\n",
    "    \n",
    "    cur =conn.cursor()\n",
    "                    \n",
    "    for i in range(len(csv_files)):\n",
    "        path = 's3://{}/{}'.format(bucket, csv_files[i])\n",
    "        try:\n",
    "            query = staging_copy.format(tables[i], path, ARN)\n",
    "            cur.execute(query)\n",
    "        except:\n",
    "            conn.rollback()\n",
    "            print('The following query failed: ', query)\n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn = connect_to_reshift(HOST, DB, DB_USER, DB_PASSWORD, 5439)\n",
    "copy_staging(conn, 'qscapstone', ['airports.csv', 'demographics.csv', 'immigration.csv'], \n",
    "             ['staging_airports', 'staging_demographics', 'staging_immigration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def insert_facts_table(conn):\n",
    "    \"\"\"Function that insertst facts table\n",
    "    Args:\n",
    "        conn (conection): psycopg2 connection\n",
    "    Returns\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    query = '''\n",
    "    INSERT INTO immigration_facts\n",
    "    (SELECT \n",
    "        si.im_id,\n",
    "        si.i94port,\n",
    "        sd.city_id,\n",
    "        si.i94cit,\n",
    "        si.i94mode,\n",
    "        si.arrdate,\n",
    "        si.i94res,\n",
    "        si.i94addr,\n",
    "        si.depDate,\n",
    "        si.i94bir,\n",
    "        si.i94visa,\n",
    "        si.gender\n",
    "    FROM\n",
    "        staging_immigration AS si INNER JOIN \n",
    "        staging_airports AS sa ON si.i94port = sa.iata_code INNER JOIN\n",
    "        staging_demographics AS sd ON sa.municipality = sd.city);\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except:\n",
    "        conn.rollback()\n",
    "        \n",
    "    conn.commit()\n",
    "    cur.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "insert_facts_table(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def insert_dimensions_table():\n",
    "    \"\"\"Function that dimensions facts table\n",
    "    Args:\n",
    "    Returns\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def perform_aggregation():\n",
    "    \"\"\"Function that performs aggregation on dimensions tables\n",
    "    Args:\n",
    "    Returns\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here\n",
    "\n",
    "def Pipeline():\n",
    "    '''Function to perform ETL\n",
    "    Args:\n",
    "    Returns:\n",
    "    '''\n",
    "    # connect to Redshift\n",
    "    conn = connect_to_reshift(HOST, DB, DB_USER, DB_PASSWORD, 5439) \n",
    "    \n",
    "    # drop tables\n",
    "    drop_tables = [\n",
    "        staging_immigration,\n",
    "        staging_airports,\n",
    "        staging_demographics\n",
    "    ]\n",
    "    \n",
    "    drop_tables(conn, drop_tables)\n",
    "    \n",
    "    # create tables\n",
    "    create_tables(conn)\n",
    "    \n",
    "    # copy staging tables\n",
    "    copy_staging(conn, 'qscapstone', ['airports.csv', 'demographics.csv', 'immigration.csv'], \n",
    "             ['staging_airports', 'staging_demographics', 'staging_immigration'])\n",
    "    \n",
    "    # insert facts table\n",
    "    insert_facts_table():\n",
    "        \n",
    "    # insert dimension tables\n",
    "    insert_dimensions_table()\n",
    "    \n",
    "    # create aggregation tables\n",
    "    perform_aggregation()\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "def check_data():\n",
    "    '''Function to perform ETL\n",
    "    Args:\n",
    "    Returns:\n",
    "    '''\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
